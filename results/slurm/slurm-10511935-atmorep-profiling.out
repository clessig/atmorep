START 2024-10-31 11:54:02
SLURM_JOB_ID=10511935
SLURM_JOB_NUM_NODES=1
SLURM_NODELIST=jwb0129
The following modules were not unloaded:
  (Use "module --force purge" to unload all):

  1) Stages/2024
devices : ['cuda:0']
[W1031 11:54:23.512262637 socket.cpp:461] [c10d] The server socket cannot be initialized on [::]:1345 (errno: 97 - Address family not supported by protocol).
[W1031 11:54:23.529447289 socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [jwb0129i.juwels]:1345 (errno: 97 - Address family not supported by protocol).
wandb: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.18.5
wandb: W&B syncing is set to `offline` in this directory.  
wandb: Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.
Wandb run: atmorep-jjp7jvhd-10511935
with_ddp : True
num_accs_per_task : 1
par_rank : 0
par_size : 1
fields : [['velocity_u', [1, 1024, [], 0], [96, 105, 114, 123, 137], [12, 3, 6], [3, 18, 18], [0.5, 0.9, 0.2, 0.05]]]
fields_prediction : [['velocity_u', 1.0]]
fields_targets : []
years_train : [2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020]
years_val : [2021]
month : None
geo_range_sampling : [[-90.0, 90.0], [0.0, 360.0]]
time_sampling : 1
torch_seed : 2925618223853972920
batch_size_validation : 1
batch_size : 96
num_epochs : 128
num_samples_per_epoch : 49152
num_samples_validate : 1536
num_loader_workers : 6
size_token_info : 8
size_token_info_net : 16
grad_checkpointing : True
with_cls : False
with_mixed_precision : True
with_layernorm : True
coupling_num_heads_per_field : 1
dropout_rate : 0.05
with_qk_lnorm : False
encoder_num_layers : 6
encoder_num_heads : 16
encoder_num_mlp_layers : 2
encoder_att_type : dense
decoder_num_layers : 6
decoder_num_heads : 16
decoder_num_mlp_layers : 2
decoder_self_att : False
decoder_cross_att_ratio : 0.5
decoder_cross_att_rate : 1.0
decoder_att_type : dense
net_tail_num_nets : 16
net_tail_num_layers : 0
losses : ['mse_ensemble', 'stats']
optimizer_zero : False
lr_start : 4.9999999999999996e-06
lr_max : 0.00015000000000000001
lr_min : 4e-05
weight_decay : 0.05
lr_decay_rate : 1.025
lr_start_epochs : 3
BERT_strategy : BERT
forecast_num_tokens : 2
BERT_fields_synced : False
BERT_mr_max : 2
log_test_num_ranks : 0
save_grads : False
profile : False
test_initial : False
attention : False
rng_seed : None
with_wandb : True
slurm_job_id : 10511935
wandb_id : jjp7jvhd
file_path : /p/scratch/atmo-rep/data/era5_1deg/months/era5_y1979_2021_res025.zarr
n_size : [36, 13.5, 27.0]
/usr/local/lib/python3.10/dist-packages/torch/nn/init.py:452: UserWarning: Initializing zero-element tensors is a no-op
  warnings.warn("Initializing zero-element tensors is a no-op")
['cuda:0'] 0
self.ds['data'] : (376944, 7, 5, 721, 1440) :: (376944,)
self.lats : (721,)
self.lons : (1440,)
/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:556: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
self.ds['data'] : (376944, 7, 5, 721, 1440) :: (376944,)
self.lats : (721,)
self.lons : (1440,)
Number of trainable parameters: 117,656,336
0 : 11:54:35 :: batch_size = 96, lr = 4.9999999999999996e-06
epoch: 0 [1/512 (0%)]	Loss: 1.23101 : 1.01345 :: 0.56445 (0.46 s/sec)
epoch: 0 [2/512 (0%)]	Loss: 1.37862 : 1.27867 :: 0.56201 (31.81 s/sec)
epoch: 0 [3/512 (1%)]	Loss: 1.27518 : 1.08700 :: 0.55859 (31.73 s/sec)
epoch: 0 [4/512 (1%)]	Loss: 1.28899 : 1.12672 :: 0.55615 (31.37 s/sec)
epoch: 0 [5/512 (1%)]	Loss: 1.18096 : 0.93993 :: 0.55322 (31.37 s/sec)
epoch: 0 [6/512 (1%)]	Loss: 1.10985 : 0.83943 :: 0.54980 (1.00 s/sec)
epoch: 0 [7/512 (1%)]	Loss: 1.20417 : 0.98709 :: 0.54785 (35.18 s/sec)
epoch: 0 [8/512 (2%)]	Loss: 1.18648 : 0.95280 :: 0.54590 (32.69 s/sec)
epoch: 0 [9/512 (2%)]	Loss: 1.25123 : 1.07782 :: 0.54297 (34.10 s/sec)
epoch: 0 [10/512 (2%)]	Loss: 1.25370 : 1.06287 :: 0.54248 (31.69 s/sec)
epoch: 0 [11/512 (2%)]	Loss: 1.17824 : 0.94717 :: 0.53955 (31.94 s/sec)
epoch: 0 [12/512 (2%)]	Loss: 1.22866 : 1.04109 :: 0.53809 (1.25 s/sec)
epoch: 0 [13/512 (3%)]	Loss: 1.16176 : 0.91895 :: 0.53613 (28.68 s/sec)
epoch: 0 [14/512 (3%)]	Loss: 1.17989 : 0.97490 :: 0.53418 (28.34 s/sec)
epoch: 0 [15/512 (3%)]	Loss: 1.23124 : 1.05916 :: 0.53369 (31.46 s/sec)
epoch: 0 [16/512 (3%)]	Loss: 1.22451 : 1.02462 :: 0.53271 (30.56 s/sec)
epoch: 0 [17/512 (3%)]	Loss: 1.11473 : 0.85956 :: 0.53076 (30.75 s/sec)
error: *** job 10511935 CANCELLED DUE TO TIME LIMIT ***
error: *** step 10511935.0 CANCELLED DUE TO TIME LIMIT ***
srun: Job step aborted: Waiting up to 6 seconds for job step to finish.
SIGBUS: bus error
PC=0x45b6d5 m=0 sigcode=2 addr=0x1c7ff38

goroutine 0 gp=0x1fd2900 m=0 mp=0x1fd3b20 [idle]:
srun: error: jwb0129: task 0: Terminated
