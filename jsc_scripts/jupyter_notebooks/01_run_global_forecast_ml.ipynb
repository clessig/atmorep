{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "772a178b-63df-4de4-b293-7a5ed4cdac0f",
   "metadata": {},
   "source": [
    "# Tutorial 1 - Forecasting with AtmoRep\n",
    "\n",
    "## Preamble\n",
    "\n",
    "Training of AtmoRep is a computationally intensive process, typically requiring a couple of weeks on multiple compute nodes of Juwels Booster. \n",
    "However, a selection of pretrained AtmoRep models (singleformers and multiformers) has been made available, enabling immediate use in so called zero-shot applications. <br>\n",
    "Zero-shot applications leverage the intrinsic capabilities of the AtmoRep model and do not require task-specific finetuning or the addition of a specialized network to the core model.\n",
    "In particular, AtmoRep has demonstrated skill for short-range forecasting/nowcasting, temporal interpolation and data decompression. <br>\n",
    "In the following, we will explore the forecast application in a zero-shot setting.\n",
    "\n",
    "#### Objectives\n",
    "The objectives of this tutorial comprise\n",
    "- Generation of a six-hour forecast with AtmoRep in inference mode\n",
    "- Handling and plotting AtmoRep's model output\n",
    "- Evaluation AtmoRep's forecast capacities\n",
    "\n",
    "### Prerequisites\n",
    "To run the following cells of the Jupyter Notebook, please ensure that you fulfill the following requirements:\n",
    "- Run your JupyterLab on the GPU node of JURECA (use the `dc-gpu`-partition)\n",
    "- Activate your hackathon kernel (see upper right corner of your Jupyter Notebook)\n",
    "\n",
    "## Step 1 - Generate a forecast with AtmoRep\n",
    "\n",
    "### Forecast Inference in AtmoRep\n",
    "\n",
    "In this section, we will demonstrate how to perform a **global forecast** using AtmoRep. \n",
    "With AtmoRep, forecasting can be achieved by *systematically masking* of the tokens along the time-dimension.\n",
    "This is illustrated in the figure below where the last two tokens along the time dimension are masked. Since each token incorporates three-hourly data, this masking will trigger a 6h-forecast. Note that AtmoRep is trained to predict *randomly* masked tokens, so the forecasting corresponds to a special masking scheme. While we will see that AtmoRep already has skill for this zero-shot application, AtmoRep's forecasting capabilities can be further enhanced by fine-tuning on the forecasting task. <br>\n",
    "\n",
    "![forecast](../img/forecast_1ml.jpg \"Data processing during forecast, with x input, y target output\")\n",
    "\n",
    "Finally, we note that global forecasting incorporates an additional 'technical challenge' since AtmoRep works on data from local neighborhoods (4D slices sampled on a global spatio-temporal grid) only. Systematic tiling is required to retreive a forecast for all grid points of the globe, but as we will see below, the sampling strategy in the code for inference can already be configured to do this. <br><br>\n",
    "So, let's start by importing some Python packages and classes from the AtmoRep code..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5a502c36-8bd1-44f2-ade9-b46c3805b41c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/p/project1/training2445/shared/atmorep/atmorep/core/trainer.py:31: DeprecationWarning: `TorchScript` support for functional optimizers is deprecated and will be removed in a future PyTorch release. Consider using the `torch.compile` optimizer instead.\n",
      "  from torch.distributed.optim import ZeroRedundancyOptimizer\n",
      "/p/project1/training2445/shared/atmorep/atmorep/transformer/tail_ensemble.py:54: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
      "  @torch.cuda.amp.custom_fwd(cast_inputs=torch.float32)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "from pathlib import Path\n",
    "from atmorep.core.evaluator import Evaluator\n",
    "from atmorep.config.config import UserConfig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f6d8468-0950-4bf0-963a-d3ca41159559",
   "metadata": {},
   "source": [
    "Before continuing, we need to set-up a user-specific configuration. <br>\n",
    "This procedures provides both, a symbolic link to the directories where pretrained models and the ERA5-data (in zarr stores) are available and the configuration of user-specific output directories for their (custom) models, their inference results (e.g. global forecasts) and their output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f381407f-a9c7-47c8-875b-352eb18f88e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "project_dir = Path(f\"/p/project/training2445/{os.environ['USER']}/atmorep/\")\n",
    "user_config = UserConfig.from_path(project_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd976890-6c74-4c31-8ddd-885899a807eb",
   "metadata": {},
   "source": [
    "In the next step, we are already ready to configure an instance of the `Evaluator`-class. \n",
    "This class allows users to perform inference on pretrained (either provided or custom) models. The class loads a pretrained model which is identified via its W&B-ID and then performs the inference step, i.e. only the forward step of the model is executed. The inference output is saved to the `results`-directory under the user-specific project directory. <br> \n",
    "Note that the `Evaluator`-class supports various modes for the inference (e.g. global forecasting) as outlined below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bf449818-d5fc-489d-9ee1-6d4786ee37f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id='wc5e2i3t'                # pre-trained multiforner\n",
    "\n",
    "mode, options = 'global_forecast', {\n",
    "                                  'dates' : [[2021, 2, 10, 12]],    # this corresponds to thh last time step of the prediction sequence\n",
    "                                  'token_overlap' : [0, 0],         # no overlapping between tiles\n",
    "                                  'forecast_num_tokens' : 2,        # corresponds to a 6h-forecast (=2x3h)\n",
    "                                  'with_pytest' : False }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1502ad5d-a6c3-4359-8be8-f026d520bb18",
   "metadata": {},
   "source": [
    "For each inference experiment, three key parameters are required:\n",
    "- `model_id`: the W&D ID that identifies the pre-trained model \n",
    "- `mode`: inference mode you wish to perform (see below)\n",
    "- `options`: the required attributes that are necessary to carry out the selected inference mode (see below)\n",
    "\n",
    "In the case of `global_forecast`, Atmorep requires the following options:\n",
    "- `'dates'`: This is a list of dates. For a single date, it should still be provided as a list containing just that one item. Each date should follow the format `[year, month, day, hour]`, representing the last timestep to be forecasted. Atmorep will load data from 36 hours before this timestamp (inclusive), then start forecasting `forecast_num_tokens` $\\times$ 3 hours backwards.\n",
    "- `'token_overlap'`: Specifies the degree of overlap between tiles (or neighborhoods).\n",
    "- `'forecast_num_tokens'`: The number of tokens to be forecasted.\n",
    "- `'with_pytest'`: Enables or disables systematic testing processes. \n",
    "\n",
    "After choosing the appropriate mode for our application (global forecasting) and setting the configuration options, we can run the inference by calling the `evaluate`-method of the class object. \n",
    "Note that the following process takes a couple of minutes to complete the process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9907e92e-4f36-4fb2-adbe-e6720b20942c",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"MASTER_ADDR\"] = str(os.environ['SLURM_JOB_NODELIST'])       # AtmoRep needs to know the hostname of the master-node\n",
    "\n",
    "# run inference\n",
    "now = time.time()\n",
    "Evaluator.evaluate( mode, model_id, options,  user_config=user_config)\n",
    "print(\"time\", time.time() - now)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c46f4c14-9ae3-48dd-b0d5-ab12922995b4",
   "metadata": {},
   "source": [
    "Ensure to track the W&B-ID that is outputted when running the inference. This ID is required to run the subsequent validation (Step 2 of this tutorial).\n",
    "\n",
    "### Other supported inference modes:\n",
    "\n",
    "#### BERT Forecast Mode\n",
    "This mode is similar to `global_forecast`, but instead of systematic tiling, random neighborhoods are sampled from the global dataset. \n",
    "```python\n",
    "mode, options = 'forecast', {'forecast_num_tokens': 2, 'num_samples_validate': 128, 'with_pytest': True}\n",
    "```\n",
    "The option `forecast_num_tokens` is the same as for `global_forecast`-mode. Thus, forecasts are generated for a time period set by `forecast_num_tokens` $\\times$ 3 hours for each neighborhood,. `num_samples_validate` sets the number of random neighborhoods that will be sampled during inference.\n",
    "\n",
    "#### BERT Masked Token Mode\n",
    "![BERT](../img/BERT_1ml.jpg \"Data processing during BERT evaluation\")\n",
    "\n",
    "Neighborhoods are selected randomly based on dates and geographic locations, in which tokens are randomly masked according to a percentage specified in the configuration file.\n",
    "```python\n",
    "mode, options = 'BERT', {'years_val': [2021], 'num_samples_validate': 128, 'with_pytest': True}\n",
    "```\n",
    "Options to configure:\n",
    "- `'years_val'`: Specifies the year from which samples will be drawn.\n",
    "- `'num_samples_validate'`: Number of validation batches, which is also the number of selected neighborhoods. A neighborhood is a patch in space and time which gets processed together (??? improve the sentence)\n",
    "\n",
    "#### Temporal Interpolation Mode\n",
    "![temporal interpolation](../img/temporal_interpol_1ml.jpg \"Data processing during temporal interpolation, with x input, y target output\")\n",
    "\n",
    "In this mode, AtmoRep fills in temporal gaps by predicting missing data for selected neighborhoods.\n",
    "\n",
    "```python\n",
    "mode, options = 'temporal_interpolation', {'idx_time_mask': [5, 6, 7], 'num_samples_validate': 128, 'with_pytest': True}\n",
    "```\n",
    "Key option explained:\n",
    "- `'idx_time_mask'`: Specifies the indices of tokens in a batch of 12 that AtmoRep will attempt to predict.\n",
    "\n",
    "## Step 2 - Process and validate the AtmoRep output\n",
    "\n",
    "The AtmoRep output from the inference step is written to zarr-stores. While the zarr Python package provides a straightforward way to read in the data, the multi-dimensional nature of the data is challenging for subsequent processing. For convenience, we make therefore of a small data interface that reads in the data and turns it into xarry DataArray with labelled dimensions. <br>\n",
    "For more information about xarray, please refer to the [docs](https://docs.xarray.dev/en/latest/getting-started-guide/index.html).\n",
    "\n",
    "Again, we start by importing an auxiliary class and a method for data retrieval and plotting, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "35df7c0a-467d-4504-abec-d201cd595139",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cartopy.crs as ccrs\n",
    "from jsc_scripts.utils_hackathon.read_atmorep_data import HandleAtmoRepData\n",
    "from jsc_scripts.utils_hackathon.plotting import plot_global_data "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "505f6695-84c4-4f97-90b3-0a5829e28506",
   "metadata": {},
   "source": [
    "Next, we initialize the AtmoRep data handler with the W&B-ID of the inference step executed above and with the results directory of AtmoRep."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7d4e5ed3-0d2b-42e1-9d04-22291c2d66ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dir = user_config.__dict__[\"results\"]\n",
    "model_id = \"idry906z4c\"                     # adapt here\n",
    "varname = \"temperature\"                     # can be changed\n",
    "\n",
    "ar_data = HandleAtmoRepData(model_id, input_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9262aefa-2a45-4ec9-8cc7-32814e3d8d02",
   "metadata": {},
   "source": [
    "Then, we can read in the forecasted and the (ground truth) reference data as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "162db528-265a-4466-86b7-60c7889eab72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start reading one zarr store...\n",
      "Start reading one zarr store...\n"
     ]
    }
   ],
   "source": [
    "da_fcst = ar_data.read_data(varname, \"pred\")\n",
    "da_ref = ar_data.read_data(varname, \"target\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dfcddd1-9afe-47cb-80ac-e353698cc17a",
   "metadata": {},
   "source": [
    "Let's have a look and check what we obtained:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18e2fe66-ae99-4530-aa5a-2236b87680b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "da_fcst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8445461-eee7-4425-be83-9142674edcf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "da_ref"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc925931-6203-478e-b5f9-002a24d85797",
   "metadata": {},
   "source": [
    "Since multi-dimensional arrays are hard to grasp, we will plot the data in the follwoing to get some more insight into AtmoRep's forecasts. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "44c6d5d9-b8ca-4f14-9a48-d6899bedca44",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "# parameters to select the data of interest\n",
    "it_idx = 0                        # index for init_time-dimension\n",
    "lead_time = 6\n",
    "vlevel = 96\n",
    "offset = -273.15                  # for conveting temperature unit from K to °C\n",
    "\n",
    "# set some parameters to customize our plots\n",
    "proj = ccrs.Robinson(central_longitude=0.)      # The projection to display the (global) data\n",
    "transform = ccrs.PlateCarree()                  # transformation-object to be used when processing the data in the plot-routne (don't change!)\n",
    "cmap_name = \"RdBu_r\"                            # colormap \n",
    "\n",
    "# slice the data of interes\n",
    "fcst, ref = da_fcst.isel({\"init_time\": it_idx}).sel({\"ml\": vlevel, \"lead_time\": lead_time}) + offset, \\\n",
    "            da_ref.isel({\"init_time\": it_idx}).sel({\"ml\": vlevel, \"lead_time\": lead_time}) + offset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03817ad8-2a3e-413f-a7cd-ddcd8b10b18c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get auxiliary strings\n",
    "init_time = pd.to_datetime(da_fcst[\"init_time\"][it_idx].values)\n",
    "fcst_str = f\"{init_time.strftime('%Y%m%d_%H00')}+{lead_time:03d}\"\n",
    "\n",
    "# create the plots - this takes a while\n",
    "fname_pred = user_config.__dict__[\"results\"].joinpath(f\"atmorep_pred_{varname}_ml{vlevel: 03d}_{fcst_str}.png\")\n",
    "plot_global_data(fcst, fname_pred,\n",
    "                 levels=np.arange(-45., 6.), cmap_name=cmap_name, projection=proj, transform=transform)\n",
    "\n",
    "fname_tar = str(fname_pred).replace(\"pred\", \"tar\") \n",
    "plot_global_data(ref, fname_tar,\n",
    "                 levels=np.arange(-45., 6.), cmap_name=cmap_name, projection=proj, transform=transform)\n",
    "\n",
    "fname_diff = str(fname_pred).replace(\"pred\", \"diff\")\n",
    "plot_global_data(fcst - ref, fname_diff,\n",
    "                 levels=np.arange(-3., 3.1, 0.1), cmap_name=cmap_name, projection=proj, transform=transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e217a0f-4175-4500-8a64-595940dbd35c",
   "metadata": {},
   "source": [
    "### Task 1:\n",
    "- Plot different variables on different levels\n",
    "- Describe what you see. Can you explain your findings?\n",
    "\n",
    "<hr> \n",
    "\n",
    "In the following, we will make our analysis more quantitative. For this, we will compute some basic evaluation metrics such as the RMSE and investigate how the results change with lead time. <br>\n",
    "Again, we don't need to code everything from scratch, but make use of a `Score`-engine that allows computation of several metrics including averaging over user-defined data dimensions. <br>\n",
    "We start by initialising the `Score`-engine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fad9ca85-e793-4202-9bc8-81b2b530a951",
   "metadata": {},
   "outputs": [],
   "source": [
    "from jsc_scripts.utils_hackathon.metrics import Scores\n",
    "\n",
    "score_engine = Scores(da_fcst, da_ref, _, [\"init_time\", \"lat\", \"lon\",])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f48db1ef-f0d6-483c-bb4c-2a4c853c4e03",
   "metadata": {},
   "source": [
    "You may consult the doc-string to get further information on the engine. Alternatively, consult the source code (`/p/project/training2445/shared/atmorep/jsc_scripts/utils_hackathon/metrics.py`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0edce801-2837-42b7-9362-763f82ee3c2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        Constructor of score engine.\n",
      "        :param data_fcst: forecast data to evaluate \n",
      "        :param data_ref: reference or ground truth data\n",
      "        :param avg_dims: dimension or list of dimensions over which scores shall be averaged. \n",
      "                         Parse 'all' to average over all data dimensions.\n",
      "        \n",
      "Available scores: ['ets', 'pss', 'fbi', 'mae', 'l1', 'l2', 'mse', 'rmse', 'bias', 'acc', 'spread', 'ssr', 'grad_amplitude', 'psnr', 'iqd', 'seeps']\n"
     ]
    }
   ],
   "source": [
    "import inspect\n",
    "print(Scores.__init__.__doc__)\n",
    "print(f\"Available scores: {list(score_engine.metrics_dict.keys())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98f7144e-7174-41c5-b4fc-4b3bac59c2d3",
   "metadata": {},
   "source": [
    "Let's calculate the RMSE and plot it against leadtime:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c3a4f74-53e3-43c4-815f-a17dc166e7e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse = score_engine(\"rmse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19a134c6-9db3-4c56-a6ed-ad1d81fd2472",
   "metadata": {},
   "outputs": [],
   "source": [
    "from jsc_scripts.utils_hackathon.plotting import plot_metric_line\n",
    "\n",
    "fname_rmse = user_config.__dict__[\"output\"].joinpath(f\"atmorep_rmse_{varname}_ml{vlevel:03d}.png\")\n",
    "\n",
    "plot_metric_line(rmse.sel({\"ml\": vlevel}), metric={\"RMSE\": \"K\"}, value_range=(0., 1.), plt_fname=str(fname_rmse), \n",
    "                 x_coord=\"lead_time\", xlabel=\"leadtime [h]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "874bce60-37b4-4cb3-bf1a-cbb178f56324",
   "metadata": {},
   "source": [
    "### Task 2:\n",
    "- Evaluate different variables on different levels\n",
    "- What do you observe?\n",
    "- Extra task: Go back to the top of the Jupyter Notebook and re-run the forecasting by modifying the maximum leadtime. How does this affect the results?\n",
    "\n",
    "<hr>\n",
    "\n",
    "## Step 3 - Process and validate the AtmoRep ensemble\n",
    "\n",
    "AtmoRep is an intrinsically probablistic model, but so far, we have just investigated the **ensemble mean** of the (global) forecast.\n",
    "In the following, we will have a look at individual ensemble members, check the ensemble variability and do some basic evaluation. Again, we can utilize our AtmoRep output data interface to read the ensemble predictions from the zarr store."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41b4f629-4a23-4083-a42b-02f94b61c206",
   "metadata": {},
   "outputs": [],
   "source": [
    "da_ens = ar_data.read_data(varname, \"ens\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a3764c1-4399-4ab4-93c1-4a9862193534",
   "metadata": {},
   "source": [
    "Now, that we have read in the ensemble forecast, let's go ahead and investigate the data. \n",
    "### Task 3:\n",
    "- Check the retrieved xarray.DataArray and pay attention to the dimensions.\n",
    "- Plot individual ensemble members as well as their differences to each other\n",
    "\n",
    "Since we have already introduced you to the auxiliary tools, get your hands dirty and start by yourself. Happy coding :-)\n",
    "\n",
    "**Hint:**\n",
    "- You may reinitialize your score-engine where the ensemble forecast data is provided as the third argument (it was blanked out above).\n",
    "- Currently, just a small number of probablistic scores is implemented in the `Score`-class. However, you may investigate the spread skill score, named 'ssr'. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8333d033-ae8c-4577-a92d-0161054d8a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot individual ensemble members\n",
    "\n",
    "iens = 0 \n",
    "plt_fname = ...\n",
    "\n",
    "# evaluate individual ensemble \n",
    "score_engine_ens = Scores(da_ens.isel({\"ensemble\": iens}), da_ref, _, [\"init_time\", \"lat\", \"lon\",])      # forecast engine for individual ensemble members\n",
    "\n",
    "# probablistic evaluation\n",
    "score_engine = Scores(da_fcst, da_ref, da_ens, [\"init_time\", \"lat\", \"lon\",])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hclimrep_hackathon",
   "language": "python",
   "name": "hclimrep_hackathon"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
